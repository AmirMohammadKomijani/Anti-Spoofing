{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m imgFace \u001b[38;5;241m=\u001b[39m img[y:y \u001b[38;5;241m+\u001b[39m h, x:x \u001b[38;5;241m+\u001b[39m w]\n\u001b[0;32m     60\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFace\u001b[39m\u001b[38;5;124m\"\u001b[39m, imgFace)\n\u001b[1;32m---> 61\u001b[0m blurValue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLaplacian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgFace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCV_64F\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvar())\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blurValue \u001b[38;5;241m>\u001b[39m blurThreshold:\n\u001b[0;32m     63\u001b[0m     listBlur\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time, sleep\n",
    "import cv2\n",
    "import cvzone\n",
    "from cvzone.FaceDetectionModule import FaceDetector\n",
    "\n",
    "####################################\n",
    "classID = 1  # 0 is fake and 1 is real\n",
    "outputFolderPath = 'Dataset/DataCollect'\n",
    "confidence = 0.8\n",
    "save = True\n",
    "blurThreshold = 35  # Larger is more focus\n",
    "\n",
    "debug = False\n",
    "offsetPercentageW = 10\n",
    "offsetPercentageH = 20\n",
    "camWidth, camHeight = 640, 480\n",
    "floatingPoint = 6\n",
    "####################################\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, camWidth)\n",
    "cap.set(4, camHeight)\n",
    "\n",
    "detector = FaceDetector()\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgOut = img.copy()\n",
    "    img, bboxs = detector.findFaces(img, draw=False)\n",
    "\n",
    "    listBlur = []  # True False values indicating if the faces are blur or not\n",
    "    listInfo = []  # The normalized values and the class name for the label txt file\n",
    "    if bboxs:\n",
    "        # bboxInfo - \"id\",\"bbox\",\"score\",\"center\"\n",
    "        for bbox in bboxs:\n",
    "            x, y, w, h = bbox[\"bbox\"]\n",
    "            score = bbox[\"score\"][0]\n",
    "            # print(x, y, w, h)\n",
    "\n",
    "            # ------  Check the score --------\n",
    "            if score > confidence:\n",
    "\n",
    "                # ------  Adding an offset to the face Detected --------\n",
    "                offsetW = (offsetPercentageW / 100) * w\n",
    "                x = int(x - offsetW)\n",
    "                w = int(w + offsetW * 2)\n",
    "                offsetH = (offsetPercentageH / 100) * h\n",
    "                # 3 and 3.5 are base of operations\n",
    "                y = int(y - offsetH * 3)\n",
    "                h = int(h + offsetH * 3.5)\n",
    "\n",
    "                # ------  To avoid values below 0 because it makes error in next part--------\n",
    "                if x < 0: x = 0\n",
    "                if y < 0: y = 0\n",
    "                if w < 0: w = 0\n",
    "                if h < 0: h = 0\n",
    "\n",
    "                # ------  Find Blurriness --------\n",
    "                imgFace = img[y:y + h, x:x + w]\n",
    "                cv2.imshow(\"Face\", imgFace)\n",
    "                blurValue = int(cv2.Laplacian(imgFace, cv2.CV_64F).var())\n",
    "                if blurValue > blurThreshold:\n",
    "                    listBlur.append(True)\n",
    "                else:\n",
    "                    listBlur.append(False)\n",
    "\n",
    "                # ------  Normalize Values  --------\n",
    "                # we need the center point to be saved \n",
    "                ih, iw, _ = img.shape\n",
    "                xc, yc = x + w / 2, y + h / 2\n",
    "                # normalize value by 6 floating point\n",
    "                # as we set ih = 480 , iw = 640\n",
    "                # xc,yc is the center point cordination\n",
    "                # normalizing w , h by division of ih , iw\n",
    "                xcn, ycn = round(xc / iw, floatingPoint), round(yc / ih, floatingPoint)\n",
    "                wn, hn = round(w / iw, floatingPoint), round(h / ih, floatingPoint)\n",
    "                # print(xcn, ycn, wn, hn)\n",
    "\n",
    "                # ------  To avoid values above 1 because we normalized the data --------\n",
    "                if xcn > 1: xcn = 1\n",
    "                if ycn > 1: ycn = 1\n",
    "                if wn > 1: wn = 1\n",
    "                if hn > 1: hn = 1\n",
    "\n",
    "                # save text with format that Yolo need\n",
    "                listInfo.append(f\"{classID} {xcn} {ycn} {wn} {hn}\\n\")\n",
    "\n",
    "                # ------  Drawing --------\n",
    "                # show image with text score and blur and \n",
    "                # save with out this texts\n",
    "                cv2.rectangle(imgOut, (x, y, w, h), (255, 0, 0), 3)\n",
    "                cvzone.putTextRect(imgOut, f'Score: {int(score * 100)}% Blur: {blurValue}', (x, y - 0),\n",
    "                                   scale=2, thickness=3)\n",
    "                # show image and save them with text score and blur\n",
    "                if debug:\n",
    "                    cv2.rectangle(img, (x, y, w, h), (255, 0, 0), 3)\n",
    "                    cvzone.putTextRect(img, f'Score: {int(score * 100)}% Blur: {blurValue}', (x, y - 0),\n",
    "                                       scale=2, thickness=3)\n",
    "\n",
    "        # ------  To Save --------\n",
    "        if save:\n",
    "            # save if all the detected part are focused\n",
    "            if all(listBlur) and listBlur != []:\n",
    "                # ------  Save Image  --------\n",
    "                timeNow = time()\n",
    "                timeNow = str(timeNow).split('.')\n",
    "                timeNow = timeNow[0] + timeNow[1]\n",
    "                cv2.imwrite(f\"{outputFolderPath}/{timeNow}.jpg\", img)\n",
    "                # ------  Save Label Text File  --------\n",
    "                for info in listInfo:\n",
    "                    f = open(f\"{outputFolderPath}/{timeNow}.txt\", 'a')\n",
    "                    f.write(info)\n",
    "                    f.close()\n",
    "\n",
    "    cv2.imshow(\"Image\", imgOut)\n",
    "    cv2.waitKey(1)\n",
    "    # sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
